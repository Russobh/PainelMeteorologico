{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from math import sqrt\n",
        "from pandas.tseries.offsets import DateOffset\n",
        "import matplotlib.pyplot as plt\n",
        "import ast\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# Ler o arquivo CSV\n",
        "caminho = 'C:\\\\TCC\\\\bases_tempo\\\\'\n",
        "df = pd.read_csv(caminho + 'dados_finais.csv', sep=',', dayfirst=True, parse_dates=['Data'], decimal=',')\n",
        "\n",
        "# Convertendo a coluna 'Data' para o formato datetime\n",
        "df['Data'] = pd.to_datetime(df['Data'], format='%d/%m/%Y')\n",
        "\n",
        "# Criando colunas para o m\u00eas e o ano\n",
        "df['Mes'] = df['Data'].dt.month\n",
        "df['Ano'] = df['Data'].dt.year\n",
        "\n",
        "# Convertendo as colunas 'Temp Comp Media' e 'Precipitacao' para num\u00e9rico\n",
        "df['Temp Comp Media'] = pd.to_numeric(df['Temp Comp Media'], errors='coerce')\n",
        "df['Precipitacao'] = pd.to_numeric(df['Precipitacao'], errors='coerce').replace(0, 1)  # Substituir 0 por 1\n",
        "\n",
        "# Agrupando os dados por esta\u00e7\u00e3o, m\u00eas e ano\n",
        "df_agrupado = df.groupby(['Estacao', 'Mes', 'Ano']).agg({'Precipitacao':'sum', 'Temp Comp Media':'mean'}).reset_index()\n",
        "\n",
        "# Calculando as varia\u00e7\u00f5es percentuais anuais por esta\u00e7\u00e3o\n",
        "df_agrupado['Varia\u00e7\u00e3o Anual Esta\u00e7\u00e3o Temp Comp Media'] = df_agrupado.groupby(['Estacao', 'Mes'])['Temp Comp Media'].pct_change(fill_method=None).round(3)\n",
        "df_agrupado['Varia\u00e7\u00e3o Anual Esta\u00e7\u00e3o Precipitacao'] = df_agrupado.groupby(['Estacao', 'Mes'])['Precipitacao'].pct_change(fill_method=None).round(3)\n",
        "\n",
        "# Agrupando os dados por m\u00eas e ano para calcular as varia\u00e7\u00f5es totais\n",
        "df_total = df.groupby(['Mes', 'Ano']).agg({'Precipitacao':'sum', 'Temp Comp Media':'mean'}).reset_index()\n",
        "\n",
        "# Calculando as varia\u00e7\u00f5es percentuais anuais totais\n",
        "df_total['Varia\u00e7\u00e3o Total Anual Temp Comp Media'] = df_total.groupby('Mes')['Temp Comp Media'].pct_change(fill_method=None).round(3)\n",
        "df_total['Varia\u00e7\u00e3o Total Anual Precipitacao'] = df_total.groupby('Mes')['Precipitacao'].pct_change(fill_method=None).round(3)\n",
        "\n",
        "# Juntando os dataframes\n",
        "df_final = pd.merge(df_agrupado, df_total[['Mes', 'Ano', 'Varia\u00e7\u00e3o Total Anual Temp Comp Media', 'Varia\u00e7\u00e3o Total Anual Precipitacao']], on=['Mes', 'Ano'])\n",
        "\n",
        "# Ler o arquivo CSV do ENSO\n",
        "dfenso = pd.read_csv(caminho + 'ENSO.csv')\n",
        "\n",
        "# Convertendo a coluna 'Date' para o formato datetime\n",
        "dfenso['Date'] = pd.to_datetime(dfenso['Date'])\n",
        "\n",
        "# Criando colunas para o m\u00eas e o ano\n",
        "dfenso['Mes'] = dfenso['Date'].dt.month\n",
        "dfenso['Ano'] = dfenso['Date'].dt.year\n",
        "\n",
        "# Selecionando apenas as colunas 'Mes', 'Ano' e 'ONI'\n",
        "dfenso = dfenso[['Mes', 'Ano', 'ONI']]\n",
        "\n",
        "# Criar a coluna ONI ajustado com ONI + 20\n",
        "dfenso['ONI_ajustado'] = dfenso['ONI'] + 20\n",
        "\n",
        "# Calcular a varia\u00e7\u00e3o mensal dos valores ONI ajustado por m\u00eas e ano\n",
        "dfenso['Varia\u00e7\u00e3o_ONI'] = dfenso.groupby('Mes')['ONI_ajustado'].pct_change().round(3)\n",
        "\n",
        "# Substituir infinito e menos infinito por NaN\n",
        "dfenso['Varia\u00e7\u00e3o_ONI'] = dfenso['Varia\u00e7\u00e3o_ONI'].replace([np.inf, -np.inf], np.nan)\n",
        "\n",
        "# Preencher NaN com a diferen\u00e7a entre o valor atual e o pr\u00f3ximo valor n\u00e3o-zero\n",
        "dfenso['Varia\u00e7\u00e3o_ONI'] = dfenso['Varia\u00e7\u00e3o_ONI'].fillna(dfenso.groupby('Mes')['ONI'].diff())\n",
        "\n",
        "# Verificar se existem dados faltantes\n",
        "if dfenso.isnull().any().any():\n",
        "    print(\"Existem dados faltantes no DataFrame do ENSO.\")\n",
        "else:\n",
        "    print(\"N\u00e3o existem dados faltantes no DataFrame.\")\n",
        "\n",
        "# Juntando os dataframes\n",
        "df_final = pd.merge(df_final, dfenso, on=['Mes', 'Ano'])\n",
        "\n",
        "# Abrindo Novo_CatalogoEstacoesConvencionais CSV \n",
        "df_estacoes = pd.read_csv(caminho + 'Novo_CatalogoEstacoesConvencionais.csv')\n",
        "\n",
        "# Selecionando as colunas \n",
        "df_estacoes = df_estacoes[['CD_ESTACAO', 'SG_ESTADO']]\n",
        "\n",
        "# Converta a coluna 'Estacao' para float e depois para int em df_final\n",
        "df_final['Estacao'] = df_final['Estacao'].astype(float).astype(int)\n",
        "\n",
        "# Converta a coluna 'CD_ESTACAO' para float e depois para int em df_estacoes\n",
        "df_estacoes['CD_ESTACAO'] = df_estacoes['CD_ESTACAO'].astype(float).astype(int)\n",
        "\n",
        "# Unincdo os DataFrame basedo na Estacao (left) e CD_ESTACAO (right)\n",
        "df_final = df_final.merge(df_estacoes, left_on='Estacao', right_on='CD_ESTACAO', how='left')\n",
        "\n",
        "# Criar uma coluna regiao\n",
        "estados_regiao = {\n",
        "    'AC': 'Norte',\n",
        "    'AL': 'Nordeste',\n",
        "    'AM': 'Norte',\n",
        "    'AP': 'Norte',\n",
        "    'BA': 'Nordeste',\n",
        "    'CE': 'Nordeste',\n",
        "    'DF': 'Centro-Oeste',\n",
        "    'ES': 'Sudeste',\n",
        "    'GO': 'Centro-Oeste',\n",
        "    'MA': 'Nordeste',\n",
        "    'MG': 'Sudeste',\n",
        "    'MS': 'Centro-Oeste',\n",
        "    'MT': 'Centro-Oeste',\n",
        "    'PA': 'Norte',\n",
        "    'PB': 'Nordeste',\n",
        "    'PE': 'Nordeste',\n",
        "    'PI': 'Nordeste',\n",
        "    'PR': 'Sul',\n",
        "    'RJ': 'Sudeste',\n",
        "    'RN': 'Nordeste',\n",
        "    'RO': 'Norte',\n",
        "    'RR': 'Norte',\n",
        "    'RS': 'Sul',\n",
        "    'SC': 'Sul',\n",
        "    'SE': 'Nordeste',\n",
        "    'SP': 'Sudeste',\n",
        "    'TO': 'Norte',\n",
        "}\n",
        "\n",
        "df_final['REGIAO'] = df_final['SG_ESTADO'].apply(lambda x: estados_regiao.get(x)).fillna('Indefinida')\n",
        "\n",
        "# Agrupando os dados por estado, m\u00eas e ano\n",
        "df_agrupado_novo = df_final.groupby(['SG_ESTADO', 'Mes', 'Ano']).agg({'Precipitacao':'sum', 'Temp Comp Media':'mean'}).reset_index()\n",
        "\n",
        "# Calculando as varia\u00e7\u00f5es percentuais anuais por estado\n",
        "df_agrupado_novo['Varia\u00e7\u00e3o Anual Estado Temp Comp Media'] = df_agrupado_novo.groupby(['SG_ESTADO', 'Mes'])['Temp Comp Media'].pct_change(fill_method=None).round(3)\n",
        "df_agrupado_novo['Varia\u00e7\u00e3o Anual Estado Precipitacao'] = df_agrupado_novo.groupby(['SG_ESTADO', 'Mes'])['Precipitacao'].pct_change(fill_method=None).round(3)\n",
        "df_agrupado_novo = pd.merge(df_agrupado_novo, dfenso, on=['Mes', 'Ano'])\n",
        "\n",
        "# Agrupando os dados por estado, m\u00eas e ano\n",
        "df_agrupado_novo2 = df_final.groupby(['REGIAO', 'Mes', 'Ano']).agg({'Precipitacao':'sum', 'Temp Comp Media':'mean'}).reset_index()\n",
        "\n",
        "# Calculando as varia\u00e7\u00f5es percentuais anuais por regiao\n",
        "df_agrupado_novo2['Varia\u00e7\u00e3o Anual Regiao Temp Comp Media'] = df_agrupado_novo2.groupby(['REGIAO', 'Mes'])['Temp Comp Media'].pct_change(fill_method=None).round(3)\n",
        "df_agrupado_novo2['Varia\u00e7\u00e3o Anual Regiao Precipitacao'] = df_agrupado_novo2.groupby(['REGIAO', 'Mes'])['Precipitacao'].pct_change(fill_method=None).round(3)\n",
        "df_agrupado_novo2 = pd.merge(df_agrupado_novo2, dfenso, on=['Mes', 'Ano'])\n",
        "# Salvar o DataFrame final como um arquivo CSV\n",
        "df_final.to_csv(caminho + 'dados_ml.csv', index=False)\n",
        "df = df_final\n",
        "\n",
        "# Lista de pares de vari\u00e1veis para calcular a correla\u00e7\u00e3o\n",
        "pares_variaveis_temp = [\n",
        "    ['Varia\u00e7\u00e3o Total Anual Temp Comp Media', 'Varia\u00e7\u00e3o_ONI'],\n",
        "    ['Temp Comp Media', 'Varia\u00e7\u00e3o_ONI'],\n",
        "    ['Varia\u00e7\u00e3o Total Anual Temp Comp Media', 'ONI'],\n",
        "    ['Temp Comp Media', 'ONI']\n",
        "]\n",
        "\n",
        "pares_variaveis_precip = [\n",
        "    ['Varia\u00e7\u00e3o Total Anual Precipitacao', 'Varia\u00e7\u00e3o_ONI'],\n",
        "    ['Precipitacao', 'Varia\u00e7\u00e3o_ONI'],\n",
        "    ['Varia\u00e7\u00e3o Total Anual Precipitacao', 'ONI'],\n",
        "    ['Precipitacao', 'ONI']\n",
        "]\n",
        "\n",
        "# Lista para armazenar os resultados\n",
        "resultados_temp = []\n",
        "resultados_precip = []\n",
        "\n",
        "# Loop atrav\u00e9s dos pares de vari\u00e1veis para calcular a correla\u00e7\u00e3o\n",
        "for variaveis in pares_variaveis_temp:\n",
        "    correlacao = df_final[variaveis].corr(method='pearson').iloc[0, 1]\n",
        "    resultados_temp.append([variaveis, correlacao])\n",
        "\n",
        "for variaveis in pares_variaveis_precip:\n",
        "    correlacao = df_final[variaveis].corr(method='pearson').iloc[0, 1]\n",
        "    resultados_precip.append([variaveis, correlacao])\n",
        "\n",
        "# Converter a lista de resultados em um DataFrame\n",
        "df_resultados_temp = pd.DataFrame(resultados_temp, columns=['Pares de Vari\u00e1veis', 'Correla\u00e7\u00e3o'])\n",
        "df_resultados_precip = pd.DataFrame(resultados_precip, columns=['Pares de Vari\u00e1veis', 'Correla\u00e7\u00e3o'])\n",
        "\n",
        "# Encontrar o par de vari\u00e1veis com a maior correla\u00e7\u00e3o\n",
        "melhor_correlacao_temp = df_resultados_temp.loc[df_resultados_temp['Correla\u00e7\u00e3o'].idxmax()]\n",
        "melhor_correlacao_precip = df_resultados_precip.loc[df_resultados_precip['Correla\u00e7\u00e3o'].idxmax()]\n",
        "\n",
        "print(f\"O par de vari\u00e1veis com a maior correla\u00e7\u00e3o para temperatura \u00e9: {melhor_correlacao_temp['Pares de Vari\u00e1veis']} com uma correla\u00e7\u00e3o de {melhor_correlacao_temp['Correla\u00e7\u00e3o']}.\")\n",
        "print(f\"O par de vari\u00e1veis com a maior correla\u00e7\u00e3o para precipita\u00e7\u00e3o \u00e9: {melhor_correlacao_precip['Pares de Vari\u00e1veis']} com uma correla\u00e7\u00e3o de {melhor_correlacao_precip['Correla\u00e7\u00e3o']}.\")\n",
        "\n",
        "# Definir a fun\u00e7\u00e3o de correla\u00e7\u00e3o\n",
        "def calculate_correlation(df, variable_name, group_column, variable_column, pair_names):\n",
        "    # Criar uma copia do df\n",
        "    df_copy = df.copy()\n",
        "\n",
        "    # Renomear a coluna baseado na variavel\n",
        "    base_column_name = f'Varia\u00e7\u00e3o Total Anual {variable_name} Comp Media'\n",
        "    new_column_name = variable_column\n",
        "    df_copy.rename(columns={base_column_name: new_column_name}, inplace=True)\n",
        "\n",
        "    # Agrupar os dados\n",
        "    grouped_data = df_copy.groupby(group_column)\n",
        "\n",
        "    # Calcular a correlacao para cada grupo\n",
        "    correlations = []\n",
        "    for group_name, group_df in grouped_data:\n",
        "        for pair_name in pair_names:\n",
        "            correlation = group_df[pair_name[0]].corr(group_df[pair_name[1]], method='pearson')\n",
        "            correlations.append((group_name, pair_name, correlation))\n",
        "\n",
        "    # Ordenar as correla\u00e7\u00f5es por valores absolutos\n",
        "    correlations.sort(key=lambda x: abs(x[2]), reverse=True)\n",
        "\n",
        "    return correlations\n",
        "\n",
        "# Estacoes (usando df_final)\n",
        "top_correlations_estacoes_temp = calculate_correlation(df_final, 'temperatura', 'Estacao', 'Temp Comp Media', [\n",
        "    ['Temp Comp Media', 'Varia\u00e7\u00e3o_ONI'],\n",
        "    ['Temp Comp Media', 'ONI']\n",
        "])\n",
        "\n",
        "top_correlations_estacoes_precip = calculate_correlation(df_final, 'precipita\u00e7\u00e3o', 'Estacao', 'Precipitacao', [\n",
        "    ['Precipitacao', 'Varia\u00e7\u00e3o_ONI'],\n",
        "    ['Precipitacao', 'ONI']\n",
        "])\n",
        "\n",
        "# Estados (usando df_dados_agrupados)\n",
        "top_correlations_estados_temp = calculate_correlation(df_agrupado_novo, 'temperatura', 'SG_ESTADO', 'Temp Comp Media', [\n",
        "    ['Varia\u00e7\u00e3o Anual Estado Temp Comp Media', 'Varia\u00e7\u00e3o_ONI'],\n",
        "    ['Temp Comp Media', 'Varia\u00e7\u00e3o_ONI'],\n",
        "    ['Varia\u00e7\u00e3o Anual Estado Temp Comp Media', 'ONI'],\n",
        "    ['Temp Comp Media', 'ONI']\n",
        "])\n",
        "\n",
        "top_correlations_estados_precip = calculate_correlation(df_agrupado_novo, 'precipita\u00e7\u00e3o', 'SG_ESTADO', 'Precipitacao', [\n",
        "    ['Varia\u00e7\u00e3o Anual Estado Precipitacao', 'Varia\u00e7\u00e3o_ONI'],\n",
        "    ['Precipitacao', 'Varia\u00e7\u00e3o_ONI'],\n",
        "    ['Varia\u00e7\u00e3o Anual Estado Precipitacao', 'ONI'],\n",
        "    ['Precipitacao', 'ONI']\n",
        "])\n",
        "\n",
        "# Regioes (usando df_dados_agrupados2)\n",
        "top_correlations_regioes_temp = calculate_correlation(df_agrupado_novo2, 'temperatura', 'REGIAO', 'Temp Comp Media', [\n",
        "    ['Varia\u00e7\u00e3o Anual Regiao Temp Comp Media', 'Varia\u00e7\u00e3o_ONI'],\n",
        "    ['Temp Comp Media', 'Varia\u00e7\u00e3o_ONI'],\n",
        "    ['Varia\u00e7\u00e3o Anual Regiao Temp Comp Media', 'ONI'],\n",
        "    ['Temp Comp Media', 'ONI']\n",
        "])\n",
        "\n",
        "top_correlations_regioes_precip = calculate_correlation(df_agrupado_novo2, 'precipita\u00e7\u00e3o', 'REGIAO', 'Precipitacao', [\n",
        "    ['Varia\u00e7\u00e3o Anual Regiao Precipitacao', 'Varia\u00e7\u00e3o_ONI'],\n",
        "    ['Precipitacao', 'Varia\u00e7\u00e3o_ONI'],\n",
        "    ['Varia\u00e7\u00e3o Anual Regiao Precipitacao', 'ONI'],\n",
        "    ['Precipitacao', 'ONI']\n",
        "])\n",
        "\n",
        "# Mostrar as melhores correla\u00e7\u00f5es por categoria\n",
        "print(\"\\nTop Correlations for Temperature by Station:\")\n",
        "for correlation in top_correlations_estacoes_temp:\n",
        "    print(f\"{correlation[0]}: {correlation[1]}: {correlation[2]:.4f}\")\n",
        "\n",
        "print(\"\\nTop Correlations for Temperature by State:\")\n",
        "for correlation in top_correlations_estados_temp:\n",
        "    print(f\"{correlation[0]}: {correlation[1]}: {correlation[2]:.4f}\")\n",
        "\n",
        "print(\"\\nTop Correlations for Temperature by Region:\")\n",
        "for correlation in top_correlations_regioes_temp:\n",
        "    print(f\"{correlation[0]}: {correlation[1]}: {correlation[2]:.4f}\")\n",
        "\n",
        "print(\"\\nTop Correlations for Precipitation by Station:\")\n",
        "for correlation in top_correlations_estacoes_precip:\n",
        "    print(f\"{correlation[0]}: {correlation[1]}: {correlation[2]:.4f}\")\n",
        "\n",
        "print(\"\\nTop Correlations for Precipitation by State:\")\n",
        "for correlation in top_correlations_estados_precip:\n",
        "    print(f\"{correlation[0]}: {correlation[1]}: {correlation[2]:.4f}\")\n",
        "\n",
        "print(\"\\nTop Correlations for Precipitation by Region:\")\n",
        "for correlation in top_correlations_regioes_precip:\n",
        "    print(f\"{correlation[0]}: {correlation[1]}: {correlation[2]:.4f}\")\n",
        "\n",
        "# Cria um DataFrame para cada categoria\n",
        "df_estacoes_temp = pd.DataFrame(top_correlations_estacoes_temp, columns=['Esta\u00e7\u00e3o', 'Pares de Vari\u00e1veis', 'Correla\u00e7\u00e3o'])\n",
        "df_estacoes_precip = pd.DataFrame(top_correlations_estacoes_precip, columns=['Esta\u00e7\u00e3o', 'Pares de Vari\u00e1veis', 'Correla\u00e7\u00e3o'])\n",
        "\n",
        "df_estados_temp = pd.DataFrame(top_correlations_estados_temp, columns=['Estado', 'Pares de Vari\u00e1veis', 'Correla\u00e7\u00e3o'])\n",
        "df_estados_precip = pd.DataFrame(top_correlations_estados_precip, columns=['Estado', 'Pares de Vari\u00e1veis', 'Correla\u00e7\u00e3o'])\n",
        "\n",
        "df_regioes_temp = pd.DataFrame(top_correlations_regioes_temp, columns=['Regi\u00e3o', 'Pares de Vari\u00e1veis', 'Correla\u00e7\u00e3o'])\n",
        "df_regioes_precip = pd.DataFrame(top_correlations_regioes_precip, columns=['Regi\u00e3o', 'Pares de Vari\u00e1veis', 'Correla\u00e7\u00e3o'])\n",
        "\n",
        "# Converta a coluna 'Esta\u00e7\u00e3o' para string nos DataFrames relevantes\n",
        "df_estacoes_temp['Esta\u00e7\u00e3o'] = df_estacoes_temp['Esta\u00e7\u00e3o'].astype(str)\n",
        "df_estacoes_precip['Esta\u00e7\u00e3o'] = df_estacoes_precip['Esta\u00e7\u00e3o'].astype(str)\n",
        "\n",
        "# Concatena todos os DataFrames\n",
        "df_final_correlacao = pd.concat([df_estacoes_temp, df_estacoes_precip, df_estados_temp, df_estados_precip, df_regioes_temp, df_regioes_precip])\n",
        "\n",
        "# Cria uma coluna com n\u00fameros absolutos\n",
        "df_estacoes_temp['Correla\u00e7\u00e3o Absoluta'] = np.abs(df_estacoes_temp['Correla\u00e7\u00e3o'])\n",
        "df_estacoes_precip['Correla\u00e7\u00e3o Absoluta'] = np.abs(df_estacoes_precip['Correla\u00e7\u00e3o'])\n",
        "\n",
        "df_estados_temp['Correla\u00e7\u00e3o Absoluta'] = np.abs(df_estados_temp['Correla\u00e7\u00e3o'])\n",
        "df_estados_precip['Correla\u00e7\u00e3o Absoluta'] = np.abs(df_estados_precip['Correla\u00e7\u00e3o'])\n",
        "\n",
        "df_regioes_temp['Correla\u00e7\u00e3o Absoluta'] = np.abs(df_regioes_temp['Correla\u00e7\u00e3o'])\n",
        "df_regioes_precip['Correla\u00e7\u00e3o Absoluta'] = np.abs(df_regioes_precip['Correla\u00e7\u00e3o'])\n",
        "\n",
        "# Retorna os dados com o MAX desse n\u00famero absoluto por esta\u00e7\u00e3o, estado, regi\u00e3o\n",
        "df_estacoes_temp_max = df_estacoes_temp.loc[df_estacoes_temp.groupby('Esta\u00e7\u00e3o')['Correla\u00e7\u00e3o Absoluta'].idxmax()]\n",
        "df_estacoes_precip_max = df_estacoes_precip.loc[df_estacoes_precip.groupby('Esta\u00e7\u00e3o')['Correla\u00e7\u00e3o Absoluta'].idxmax()]\n",
        "\n",
        "df_estados_temp_max = df_estados_temp.loc[df_estados_temp.groupby('Estado')['Correla\u00e7\u00e3o Absoluta'].idxmax()]\n",
        "df_estados_precip_max = df_estados_precip.loc[df_estados_precip.groupby('Estado')['Correla\u00e7\u00e3o Absoluta'].idxmax()]\n",
        "\n",
        "df_regioes_temp_max = df_regioes_temp.loc[df_regioes_temp.groupby('Regi\u00e3o')['Correla\u00e7\u00e3o Absoluta'].idxmax()]\n",
        "df_regioes_precip_max = df_regioes_precip.loc[df_regioes_precip.groupby('Regi\u00e3o')['Correla\u00e7\u00e3o Absoluta'].idxmax()]\n",
        "\n",
        "# Cria o mapa de dispers\u00e3o\n",
        "plt.figure(figsize=(15, 10))\n",
        "plt.scatter(df_estacoes_temp_max['Esta\u00e7\u00e3o'], df_estacoes_temp_max['Correla\u00e7\u00e3o'], color='blue')\n",
        "plt.title('Mapa de Dispers\u00e3o para Temperatura por Esta\u00e7\u00e3o')\n",
        "plt.xlabel('Esta\u00e7\u00e3o')\n",
        "plt.ylabel('Correla\u00e7\u00e3o')\n",
        "# Rotaciona os r\u00f3tulos do eixo x e diminui o tamanho da fonte\n",
        "plt.xticks(rotation='vertical', fontsize='small')\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(15, 10))\n",
        "plt.scatter(df_estacoes_precip_max['Esta\u00e7\u00e3o'], df_estacoes_precip_max['Correla\u00e7\u00e3o'], color='blue')\n",
        "plt.title('Mapa de Dispers\u00e3o para Precipita\u00e7\u00e3o por Esta\u00e7\u00e3o')\n",
        "plt.xlabel('Esta\u00e7\u00e3o')\n",
        "plt.ylabel('Correla\u00e7\u00e3o')\n",
        "# Rotaciona os r\u00f3tulos do eixo x e diminui o tamanho da fonte\n",
        "plt.xticks(rotation='vertical', fontsize='small')\n",
        "plt.show()\n",
        "\n",
        "# Cria um mapa de dispers\u00e3o para temperatura para cada Estado\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(df_estados_temp_max['Estado'], df_estados_temp_max['Correla\u00e7\u00e3o'], color='red')\n",
        "plt.title('Mapa de Dispers\u00e3o para Temperatura por Estado')\n",
        "plt.xlabel('Estado')\n",
        "plt.ylabel('Correla\u00e7\u00e3o')\n",
        "plt.show()\n",
        "\n",
        "# Cria um mapa de dispers\u00e3o para precipita\u00e7\u00e3o para cada Estado\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(df_estados_precip_max['Estado'], df_estados_precip_max['Correla\u00e7\u00e3o'], color='red')\n",
        "plt.title('Mapa de Dispers\u00e3o para Precipita\u00e7\u00e3o por Estado')\n",
        "plt.xlabel('Estado')\n",
        "plt.ylabel('Correla\u00e7\u00e3o')\n",
        "plt.show()\n",
        "\n",
        "# Cria um mapa de dispers\u00e3o para temperatura para cada Regi\u00e3o\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(df_regioes_temp_max['Regi\u00e3o'], df_regioes_temp_max['Correla\u00e7\u00e3o'], color='green')\n",
        "plt.title('Mapa de Dispers\u00e3o para Temperatura por Regi\u00e3o')\n",
        "plt.xlabel('Regi\u00e3o')\n",
        "plt.ylabel('Correla\u00e7\u00e3o')\n",
        "plt.show()\n",
        "\n",
        "# Cria um mapa de dispers\u00e3o para precipita\u00e7\u00e3o para cada Regi\u00e3o\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(df_regioes_precip_max['Regi\u00e3o'], df_regioes_precip_max['Correla\u00e7\u00e3o'], color='green')\n",
        "plt.title('Mapa de Dispers\u00e3o para Precipita\u00e7\u00e3o por Regi\u00e3o')\n",
        "plt.xlabel('Regi\u00e3o')\n",
        "plt.ylabel('Correla\u00e7\u00e3o')\n",
        "plt.show()\n",
        "\n",
        "# Exporta o DataFrame final para um arquivo CSV\n",
        "df_final_correlacao.to_csv(caminho + 'correlacoes.csv', index=False)\n",
        "\n",
        "df_final.to_csv(caminho + 'correlacao_dados_estacao.csv', index=False)\n",
        "df_agrupado_novo.to_csv(caminho + 'correlacao_dados_estado.csv', index=False)\n",
        "df_agrupado_novo2.to_csv(caminho + 'correlacao_dados_regiao.csv', index=False)\n",
        "\n",
        "# Obt\u00e9m os valores absolutos da correla\u00e7\u00e3o\n",
        "df_final_correlacao['Correla\u00e7\u00e3o Absoluta'] = df_final_correlacao['Correla\u00e7\u00e3o'].apply(np.abs)\n",
        "\n",
        "# Ordena o DataFrame pela correla\u00e7\u00e3o absoluta em ordem decrescente\n",
        "df_final_correlacao = df_final_correlacao.sort_values(by='Correla\u00e7\u00e3o Absoluta', ascending=False)\n",
        "\n",
        "# Obt\u00e9m as 5 primeiras esta\u00e7\u00f5es\n",
        "primeiras_estacoes = df_final_correlacao['Esta\u00e7\u00e3o'].dropna().unique()[:2]\n",
        "\n",
        "# Obt\u00e9m os 3 primeiros estados\n",
        "primeiros_estados = df_final_correlacao['Estado'].dropna().unique()[:2]\n",
        "\n",
        "# Obt\u00e9m a primeira regi\u00e3o\n",
        "primeira_regiao = df_final_correlacao['Regi\u00e3o'].dropna().unique()[:1]\n",
        "\n",
        "print(primeiras_estacoes)\n",
        "print(primeiros_estados)\n",
        "print(primeira_regiao)\n",
        "\n",
        "# Convertendo lista de esta\u00e7\u00f5es para INT\n",
        "primeiras_estacoes_int = [int(estacao) for estacao in primeiras_estacoes]\n",
        "\n",
        "#Filtrando \n",
        "regressao_estacoes = df_final.loc[df_final['Estacao'].dropna().isin(primeiras_estacoes_int).reset_index(drop=True)]\n",
        "regressao_estados = df_agrupado_novo.loc[df_agrupado_novo['SG_ESTADO'].dropna().isin(primeiros_estados).reset_index(drop=True)]\n",
        "regressao_regiao = df_agrupado_novo2.loc[df_agrupado_novo2['REGIAO'].dropna().isin(primeira_regiao).reset_index(drop=True)]\n",
        "\n",
        "stations = regressao_estacoes['Estacao'].unique()  # Retorna as esta\u00e7\u00f5es\n",
        "estados = regressao_estados['SG_ESTADO'].unique()  # Retorna os estados\n",
        "regiao = regressao_regiao['REGIAO'].unique()  # Retorna a regiao\n",
        "\n",
        "for station in stations:\n",
        "    # Filtrar por esta\u00e7\u00e3o\n",
        "    station_data = regressao_estacoes[regressao_estacoes['Estacao'] == station]\n",
        "\n",
        "    # Substituir Inf por NaN\n",
        "    station_data = station_data.replace([np.inf, -np.inf], np.nan)\n",
        "\n",
        "    # Excluir linhas com NaN\n",
        "    station_data = station_data.dropna(subset=['Temp Comp Media', 'Varia\u00e7\u00e3o_ONI'])\n",
        "\n",
        "    # Preparando os dados\n",
        "    y = station_data['Temp Comp Media'].values\n",
        "    X = station_data[['Ano','Varia\u00e7\u00e3o_ONI']].values\n",
        "\n",
        "    # Criando o modelo\n",
        "    model = LinearRegression()\n",
        "    model.fit(X, y)\n",
        "\n",
        "    # Predicao\n",
        "    predicted_y = model.predict(X)\n",
        "\n",
        "    # Calculando o MSE e o R\u00b2\n",
        "    mse = mean_squared_error(y, predicted_y)\n",
        "    r2 = r2_score(y, predicted_y)\n",
        "\n",
        "    print(\"Esta\u00e7\u00f5es: Temperatura\")\n",
        "    print(f\"MSE: {mse}\")\n",
        "    print(f\"R\u00b2: {r2}\")\n",
        "\n",
        "    # Criando grafico\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.scatter(X[:, 0], y, label='Observed', alpha=0.7)  # Ano (year) on x-axis\n",
        "    plt.plot(X[:, 0], predicted_y, label='Predicted', color='red')\n",
        "    plt.xlabel('Ano')\n",
        "    plt.ylabel('Temp Comp Media')\n",
        "    plt.title(f\"Temperatura - Station: {station}\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "for station in stations:\n",
        "    # Filtrar por esta\u00e7\u00e3o\n",
        "    station_data = regressao_estacoes[regressao_estacoes['Estacao'] == station]\n",
        "\n",
        "    # Substituir Inf por NaN\n",
        "    station_data = station_data.replace([np.inf, -np.inf], np.nan)\n",
        "\n",
        "    # Excluir linhas com NaN\n",
        "    station_data = station_data.dropna(subset=['Precipitacao', 'ONI'])\n",
        "\n",
        "    # Preparando os dados\n",
        "    y = station_data['Precipitacao'].values\n",
        "    X = station_data[['Ano','ONI']].values\n",
        "\n",
        "    # Criando o modelo\n",
        "    model = LinearRegression()\n",
        "    model.fit(X, y)\n",
        "\n",
        "    # Predicao\n",
        "    predicted_y = model.predict(X)\n",
        "\n",
        "    # Calculando o MSE e o R\u00b2\n",
        "    mse = mean_squared_error(y, predicted_y)\n",
        "    r2 = r2_score(y, predicted_y)\n",
        "\n",
        "    print(\"Esta\u00e7\u00f5es: Precipita\u00e7\u00e3o\")\n",
        "    print(f\"MSE: {mse}\")\n",
        "    print(f\"R\u00b2: {r2}\")\n",
        "    \n",
        "    # Criando grafico\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.scatter(X[:, 0], y, label='Observed', alpha=0.7)  # Ano (year) on x-axis\n",
        "    plt.plot(X[:, 0], predicted_y, label='Predicted', color='red')\n",
        "    plt.xlabel('Ano')\n",
        "    plt.ylabel('Precipitacao')\n",
        "    plt.title(f\"Precipita\u00e7\u00e3o - Station: {station}\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "for estado in estados:\n",
        "    # Filtrar por esta\u00e7\u00e3o\n",
        "    estado_data = regressao_estados[regressao_estados['SG_ESTADO'] == estado]\n",
        "\n",
        "    # Substituir Inf por NaN\n",
        "    estado_data = estado_data.replace([np.inf, -np.inf], np.nan)\n",
        "\n",
        "    # Excluir linhas com NaN\n",
        "    estado_data = estado_data.dropna(subset=['Varia\u00e7\u00e3o Anual Estado Temp Comp Media', 'Varia\u00e7\u00e3o_ONI'])\n",
        "\n",
        "    # Preparando os dados\n",
        "    y = estado_data['Varia\u00e7\u00e3o Anual Estado Temp Comp Media'].values\n",
        "    X = estado_data[['Ano','Varia\u00e7\u00e3o_ONI']].values\n",
        "\n",
        "    # Criando o modelo\n",
        "    model = LinearRegression()\n",
        "    model.fit(X, y)\n",
        "\n",
        "    # Predicao\n",
        "    predicted_y = model.predict(X)\n",
        "\n",
        "    # Calculando o MSE e o R\u00b2\n",
        "    mse = mean_squared_error(y, predicted_y)\n",
        "    r2 = r2_score(y, predicted_y)\n",
        "\n",
        "    print(\"Estados: Temperatura\")\n",
        "    print(f\"MSE: {mse}\")\n",
        "    print(f\"R\u00b2: {r2}\")\n",
        "\n",
        "    # Criando grafico\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.scatter(X[:, 0], y, label='Observed', alpha=0.7)  # Ano (year) on x-axis\n",
        "    plt.plot(X[:, 0], predicted_y, label='Predicted', color='red')\n",
        "    plt.xlabel('Ano')\n",
        "    plt.ylabel('Varia\u00e7\u00e3o Anual Estado Temp Comp Media')\n",
        "    plt.title(f\"Temperatura - Estado: {estado}\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "for estado in estados:\n",
        "    # Filtrar por esta\u00e7\u00e3o\n",
        "    estado_data = regressao_estados[regressao_estados['SG_ESTADO'] == estado]\n",
        "\n",
        "    # Substituir Inf por NaN\n",
        "    estado_data = estado_data.replace([np.inf, -np.inf], np.nan)\n",
        "\n",
        "    # Excluir linhas com NaN\n",
        "    estado_data = estado_data.dropna(subset=['Precipitacao', 'ONI'])\n",
        "\n",
        "    # Preparando os dados\n",
        "    y = estado_data['Precipitacao'].values\n",
        "    X = estado_data[['Ano','ONI']].values\n",
        "\n",
        "    # Criando o modelo\n",
        "    model = LinearRegression()\n",
        "    model.fit(X, y)\n",
        "\n",
        "    # Predicao\n",
        "    predicted_y = model.predict(X)\n",
        "\n",
        "    # Calculando o MSE e o R\u00b2\n",
        "    mse = mean_squared_error(y, predicted_y)\n",
        "    r2 = r2_score(y, predicted_y)\n",
        "\n",
        "    print(\"Estados: Temperatura\")\n",
        "    print(f\"MSE: {mse}\")\n",
        "    print(f\"R\u00b2: {r2}\")\n",
        "\n",
        "    # Criando grafico\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.scatter(X[:, 0], y, label='Observed', alpha=0.7)  # Ano (year) on x-axis\n",
        "    plt.plot(X[:, 0], predicted_y, label='Predicted', color='red')\n",
        "    plt.xlabel('Ano')\n",
        "    plt.ylabel('Precipitacao')\n",
        "    plt.title(f\"Precipita\u00e7\u00e3o - Estado: {estado}\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "lista_regioes = regiao\n",
        "for regiao in lista_regioes:\n",
        "    # Filtrar por esta\u00e7\u00e3o\n",
        "    regiao_data = regressao_regiao[regressao_regiao['REGIAO'] == regiao]\n",
        "    \n",
        "    # Substituir Inf por NaN\n",
        "    regiao_data = regiao_data.replace([np.inf, -np.inf], np.nan)\n",
        "\n",
        "    # Excluir linhas com NaN\n",
        "    regiao_data = regiao_data.dropna(subset=['Temp Comp Media', 'ONI'])\n",
        "\n",
        "    # Preparando os dados\n",
        "    y = regiao_data['Temp Comp Media'].values\n",
        "    X = regiao_data[['Ano','ONI']].values\n",
        "\n",
        "    # Criando o modelo\n",
        "    model = LinearRegression()\n",
        "    model.fit(X, y)\n",
        "\n",
        "    # Predicao\n",
        "    predicted_y = model.predict(X)\n",
        "\n",
        "    # Calculando o MSE e o R\u00b2\n",
        "    mse = mean_squared_error(y, predicted_y)\n",
        "    r2 = r2_score(y, predicted_y)\n",
        "\n",
        "    print(\"Regi\u00e3o: Temperatura\")\n",
        "    print(f\"MSE: {mse}\")\n",
        "    print(f\"R\u00b2: {r2}\")\n",
        "\n",
        "    # Criando grafico\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.scatter(X[:, 0], y, label='Observed', alpha=0.7)  # Ano (year) on x-axis\n",
        "    plt.plot(X[:, 0], predicted_y, label='Predicted', color='red')\n",
        "    plt.xlabel('Ano')\n",
        "    plt.ylabel('Temp Comp Media')\n",
        "    plt.title(f\"Temperatura - Regi\u00e3o: {regiao}\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "for regiao in lista_regioes:\n",
        "    # Filtrar por esta\u00e7\u00e3o\n",
        "    # regiao_data = regressao_regiao[regressao_regiao['REGIAO'] == regiao]\n",
        "\n",
        "    # Substituir Inf por NaN\n",
        "    # regiao_data = regiao_data.replace([np.inf, -np.inf], np.nan)\n",
        "\n",
        "    # Excluir linhas com NaN\n",
        "    regiao_data = regiao_data.dropna(subset=['Varia\u00e7\u00e3o Anual Regiao Precipitacao', 'Varia\u00e7\u00e3o_ONI'])\n",
        "    regiao_data.to_csv(caminho + 'teste.csv')\n",
        "    # Preparando os dados\n",
        "    y = regiao_data['Varia\u00e7\u00e3o Anual Regiao Precipitacao'].values\n",
        "    X = regiao_data[['Ano','Varia\u00e7\u00e3o_ONI']].values\n",
        "\n",
        "    # Criando o modelo\n",
        "    model = LinearRegression()\n",
        "    model.fit(X, y)\n",
        "\n",
        "    # Predicao\n",
        "    predicted_y = model.predict(X)\n",
        "\n",
        "    # Calculando o MSE e o R\u00b2\n",
        "    mse = mean_squared_error(y, predicted_y)\n",
        "    r2 = r2_score(y, predicted_y)\n",
        "\n",
        "    print(\"Regi\u00e3o: Precipita\u00e7\u00e3o\")\n",
        "    print(f\"MSE: {mse}\")\n",
        "    print(f\"R\u00b2: {r2}\")\n",
        "\n",
        "    # Criando grafico\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.scatter(X[:, 0], y, label='Observed', alpha=0.7)  # Ano (year) on x-axis\n",
        "    plt.plot(X[:, 0], predicted_y, label='Predicted', color='red')\n",
        "    plt.xlabel('Ano')\n",
        "    plt.ylabel('Varia\u00e7\u00e3o Anual Regiao Precipitacao')\n",
        "    plt.title(f\"Precipita\u00e7\u00e3o - Regi\u00e3o: {regiao}\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}